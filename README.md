# POS FIAP ALURA - IA PARA DEVS - HACKATHON

## Integrantes Grupo 26

- AndrÃ© Philipe Oliveira de Andrade (RM357002) - andrepoandrade@gmail.com  
- Joir Neto (RM356391) - joirneto@gmail.com  
- Marcos Jen San Hsie (RM357422) - marcosjsh@gmail.com  
- Michael dos Santos Silva (RM357009) - michael.shel96@gmail.com  
- Sonival dos Santos (RM356905) - sonival.santos@gmail.com  

VÃ­deo (YouTube): https://youtu.be/jWyHVtRH0hs

GitHub: https://github.com/marcosjsh/fiap-hackathon.git

---

# SituaÃ§Ã£o Problema

## DetecÃ§Ã£o de materiais cortantes

A FIAP VisionGuard, empresa de monitoramento de cÃ¢meras de seguranÃ§a, estÃ¡ analisando a viabilidade de uma nova funcionalidade para otimizar o seu software.
O objetivo da empresa Ã© usar de novas tecnologias para identificar situaÃ§Ãµes atÃ­picas e que possam colocar em risco a seguranÃ§a de estabelecimentos e comÃ©rcios que utilizam suas cÃ¢meras.
Um dos principais desafios da empresa Ã© utilizar InteligÃªncia Artificial para identificar objetos cortantes (facas, tesouras e similares) e emitir alertas para a central de seguranÃ§a.
A empresa tem o objetivo de validar a viabilidade dessa feature, e para isso, serÃ¡ necessÃ¡rio fazer um MVP para detecÃ§Ã£o supervisionada desses objetos.

### Objetivos
- Construir ou buscar um dataset contendo imagens de facas, tesouras e outros objetos cortantes em diferentes condiÃ§Ãµes de Ã¢ngulo e iluminaÃ§Ã£o;
- Anotar o dataset para treinar o modelo supervisionado, incluindo imagens negativas (sem objetos perigosos) para reduzir falsos positivos;
- Treinar o modelo;
- Desenvolver um sistema de alertas (pode ser um e-mail).

### Entregas
- DocumentaÃ§Ã£o detalhando o fluxo utilizado para o desenvolvimento da soluÃ§Ã£o;
- VÃ­deo de atÃ© 15 minutos explicando a soluÃ§Ã£o proposta;
- Link do github do projeto.

---

# ğŸ§  Por que escolhemos o YOLOv5 para detecÃ§Ã£o de objetos cortantes?

## ğŸ“Œ Modelos considerados

Antes de definir o modelo ideal para a detecÃ§Ã£o de objetos cortantes, avaliamos as seguintes abordagens:

- **YOLOv4**: Um modelo extremamente popular e robusto, ainda muito utilizado em aplicaÃ§Ãµes industriais. Seu desempenho Ã© confiÃ¡vel, especialmente com imagens complexas, mas a configuraÃ§Ã£o e o treinamento costumam ser menos intuitivos em comparaÃ§Ã£o com versÃµes mais modernas.

- **YOLOv5**: Framework de detecÃ§Ã£o de objetos consolidado, amplamente utilizado na indÃºstria e comunidade cientÃ­fica, com Ã³timo desempenho em tarefas prÃ¡ticas e excelente compatibilidade com datasets customizados.

- **YOLOv8**: Arquitetura mais recente da linha YOLO, com suporte modular e tÃ©cnicas avanÃ§adas de augmentaÃ§Ã£o. Embora promissor, apresentou resultados inferiores em nossos experimentos com imagens reais.

- **CLIP + SAM / Florence2**: Modelos multimodais voltados a tarefas de classificaÃ§Ã£o, segmentaÃ§Ã£o e anÃ¡lise semÃ¢ntica. Embora impressionantes em capacidades gerais, nÃ£o se mostraram eficazes para detecÃ§Ã£o precisa de mÃºltiplos objetos cortantes em imagens reais. Apesar de suas capacidades multimodais, modelos como CLIP e SAM nÃ£o sÃ£o projetados nativamente para tarefas de detecÃ§Ã£o com bounding boxes, sendo mais adequados para classificaÃ§Ã£o sem supervisÃ£o ou segmentaÃ§Ã£o interativa

## âš–ï¸ Comparativo entre modelos

| Modelo         | PrÃ³s                                                             | Contras                                                           | Ideal para...                               |
|----------------|------------------------------------------------------------------|-------------------------------------------------------------------|---------------------------------------------|
| **YOLOv4**     | EstÃ¡vel, ainda muito utilizado, bom desempenho geral            | Setup mais complexo, menos integrado com ferramentas modernas     | Ambientes legados ou industriais             |
| **YOLOv5**     | Ã“tima performance, simples de usar, altamente compatÃ­vel         | Levemente menos â€œmodernoâ€ que YOLOv8                             | Projetos reais, com datasets customizados    |
| YOLOv8         | Arquitetura moderna, suporte nativo a augmentaÃ§Ãµes              | Desempenho inferior no nosso caso prÃ¡tico                        | Casos onde modularidade Ã© prioridade         |
| CLIP + SAM     | Capacidade multimodal, bom para zero-shot e anÃ¡lise semÃ¢ntica   | NÃ£o serve para detecÃ§Ã£o precisa com bounding boxes               | ClassificaÃ§Ã£o ou segmentaÃ§Ã£o exploratÃ³ria    |
| Florence2      | Potente e versÃ¡til                                              | Muito pesado e complexo                                           | Pesquisa avanÃ§ada e aplicaÃ§Ãµes semÃ¢nticas    |

---

## ğŸ§¬ Comparativo entre variantes do YOLOv5

| Variante      | ParÃ¢metros | Tamanho do Modelo | Velocidade (FPS) | PrecisÃ£o (mAP@0.5) | Ideal para...                  |
|---------------|------------|-------------------|------------------|--------------------|--------------------------------|
| **YOLOv5n**   | ~1.9M      | ğŸª¶ Muito leve       | ğŸš€ Muito rÃ¡pida   | MÃ©dia              | Edge, mobile, inferÃªncia leve |
| **YOLOv5s**   | ~7.5M      | ğŸ§© Leve             | ğŸš€ RÃ¡pida         | Alta               | Colab, desktop, tempo real     |
| **YOLOv5m**   | ~21.2M     | âš–ï¸ MÃ©dia            | âš¡ Boa            | Muito alta         | Servidores, GPUs maiores       |
| **YOLOv5l**   | ~46.5M     | ğŸ‹ï¸ Pesado           | MÃ©dia             | Excelente          | Treinamento robusto com GPU    |
| **YOLOv5x**   | ~87.7M     | ğŸ§  Muito pesado     | Lenta             | AltÃ­ssima          | Projetos com infraestrutura avanÃ§ada |

---

## âœ… Resumo da escolha

O **YOLOv5** (variante `s`) foi adotado por apresentar o melhor equilÃ­brio entre:

- ğŸš€ Velocidade de inferÃªncia
- ğŸ¯ PrecisÃ£o com nosso dataset especÃ­fico
- ğŸ’» Compatibilidade com Google Colab + GPU T4
- âš™ï¸ Simplicidade de uso e integraÃ§Ã£o com ferramentas modernas

# Montagem do dataset


## ğŸ§© Montagem e UnificaÃ§Ã£o do Dataset de Objetos Cortantes

Para garantir um bom desempenho do modelo YOLOv5 mesmo em ambientes com recursos computacionais limitados, foi necessÃ¡rio dedicar um pouco mais de esforÃ§o Ã  montagem de um **dataset pequeno, mas com boa qualidade e diversidade**. A ideia foi garantir representatividade visual com variaÃ§Ãµes de **Ã¢ngulo, iluminaÃ§Ã£o, contexto e tipos de objetos cortantes**, sem sobrecarregar o processo de treinamento.

---

## ğŸ” Por que usar o Roboflow Universe?

A ferramenta [Roboflow Universe](https://universe.roboflow.com/) foi escolhida por vÃ¡rios motivos:

- âœ… Disponibilidade de **diversos datasets rotulados** de forma pÃºblica e gratuita
- âœ… Interface prÃ¡tica para **prÃ©-visualizaÃ§Ã£o**, **filtragem por classe** e **download no formato YOLOv8**
- âœ… Suporte para **datasets por versÃ£o**, mantendo controle das origens
- âœ… Facilidade de exportaÃ§Ã£o padronizada (`images/` e `labels/` por split)

---

### ğŸ“¥ 1. Coleta dos Datasets

Realizou-se uma **pesquisa ativa por conjuntos de dados pÃºblicos no Roboflow Universe**, com foco nas seguintes classes:

```python
["knife", "scissor", "cutter"]
```

Cada classe foi buscada individualmente, selecionando projetos com imagens reais, bounding boxes precisos e variaÃ§Ãµes visuais significativas. Os datasets foram entÃ£o baixados e organizados em pastas separadas por classe.
A contagem original de arquivos Ã© a seguinte:

#### ğŸ“‚ Train
| Categoria    | Imagens |
|--------------|---------|
| knife        | 1627    |
| scissor      | 2050    |
| cutter       | 862     |

#### ğŸ“‚ Valid
| Categoria    | Imagens |
|--------------|---------|
| knife        | 162     |
| scissor      | 199     |
| cutter       | 117     |

#### ğŸ“‚ Test
| Categoria    | Imagens |
|--------------|---------|
| knife        | 72      |
| scissor      | 100     |
| cutter       | 31      |


---

### ğŸ§© 2. UnificaÃ§Ã£o dos Datasets

Como os datasets coletados possuÃ­am diferentes **estruturas e Ã­ndices de classes**, tornou-se necessÃ¡rio unificÃ¡-los.

Para isso, foi utilizado o script `unificar-dataset-e-atualizar-indice-e-subsampling.py`, presente na pasta `tools`, que:

- ğŸ—ƒï¸ Agrupa todos os arquivos em uma estrutura comum (`test/images`, `train/images`, `valid/images`)
- ğŸ”„ Atualiza os arquivos de rÃ³tulo `.txt` para refletirem os **Ã­ndices padronizados**

Essa etapa garante que os dados estejam **prontos para o treinamento em YOLOv5**, com consistÃªncia entre `data.yaml`, as imagens e os rÃ³tulos.

---

### âœ‚ï¸ 3. Subsampling durante a unificaÃ§Ã£o

Durante o processo de unificaÃ§Ã£o, foi aplicado um **subsampling** para limitar a quantidade de exemplos das categorias knife e scissor:

- ğŸ” **MÃ¡ximo de 1.000 imagens para as categorias alvo**
- ğŸ¯ Isso evita sobrecarregar a memÃ³ria e acelera o processo de treinamento
- âš–ï¸ Ajuda a **balancear o dataset**, evitando que uma classe como `"knife"` e `"scissor"` domine o aprendizado

---

#### Resultado do Subsampling

##### ğŸ“‚ Train
| Categoria    | Imagens |
|--------------|---------|
| knife        | 1000    |
| scissor      | 1000    |
| cutter       | 862     |


TambÃ©m foram adicionados ao dataset de train, cerca de 100 imagens de botas e grampeadores com o intuito de sujar o dataset.


##### ğŸ“‚ Valid
| Categoria    | Imagens Ãºnicas |
|--------------|----------------|
| knife        | 162            |
| scissor      | 199            |
| cutter       | 177            |



# ğŸ§ª SuperaugmentaÃ§Ã£o de Dados com Albumentations para YOLOv5

A superaugmentaÃ§Ã£o de datasets Ã© fundamental para melhorar a performance de modelos como o YOLOv5, especialmente em cenÃ¡rios com poucos dados. Ela amplia artificialmente o conjunto de imagens por meio de transformaÃ§Ãµes como rotaÃ§Ãµes, mudanÃ§as de brilho, cortes, ruÃ­dos e variaÃ§Ãµes geomÃ©tricas. Isso ajuda o modelo a aprender a detectar objetos sob diferentes condiÃ§Ãµes, evitando o overfitting e melhorando sua capacidade de generalizaÃ§Ã£o para situaÃ§Ãµes do mundo real.

AlÃ©m disso, a superaugmentaÃ§Ã£o torna o detector mais robusto, simulando variaÃ§Ãµes que os objetos podem apresentar em contextos reais, como diferentes fundos, iluminaÃ§Ãµes, Ã¢ngulos e oclusÃµes. Assim, o modelo se torna mais confiÃ¡vel em aplicaÃ§Ãµes prÃ¡ticas, como seguranÃ§a, onde objetos como facas e tesouras podem aparecer de formas imprevisÃ­veis.

Obs: O nosso dataset enviado neste repositÃ³rio jÃ¡ conta com superaugmentaÃ§Ã£o.

---

## ğŸ‹ï¸â€â™‚ï¸ Treinamento

```python
model.train(
    data='/content/drive/dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=32,
    device=0,
    workers=2,
    name='sharped-vs-nonsharped-v1',
    pretrained=True,
    augment=True,
    mosaic=1.0,
    mixup=0.2,
    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,
    flipud=0.3, fliplr=0.5,
    degrees=10.0, translate=0.1, scale=0.5, shear=2.0,
    patience=20
)
```

### âœ… ParÃ¢metros explicados:

| ParÃ¢metro         | Significado                                                                 |
|------------------|-----------------------------------------------------------------------------|
| `data`           | Caminho para o arquivo `data.yaml` com caminhos e nomes das classes         |
| `epochs`         | NÃºmero mÃ¡ximo de Ã©pocas de treinamento                                      |
| `imgsz`          | Tamanho da imagem (redimensionamento para 640x640)                          |
| `batch`          | Tamanho do batch (quantidade de imagens por iteraÃ§Ã£o)                      |
| `device`         | GPU a ser usada (`0` para a primeira GPU disponÃ­vel)                        |
| `workers`        | NÃºmero de workers para carregar dados em paralelo                           |
| `name`           | Nome do experimento (usado para salvar logs, pesos e mÃ©tricas)              |
| `pretrained`     | Usa pesos prÃ©-treinados do COCO (se `True`)                                 |
| `augment`        | Ativa augmentaÃ§Ãµes bÃ¡sicas (como flips e mudanÃ§as de brilho/contraste)      |
| `mosaic`         | Ativa **Mosaic augmentation** (1.0 = 100% das imagens usam mosaic)          |
| `mixup`          | Ativa **MixUp augmentation** com 20% de intensidade                         |
| `hsv_h/s/v`      | VariaÃ§Ãµes de tonalidade, saturaÃ§Ã£o e brilho                                 |
| `flipud`         | Probabilidade de flip vertical                                              |
| `fliplr`         | Probabilidade de flip horizontal                                            |
| `degrees`        | RotaÃ§Ã£o aleatÃ³ria de atÃ© Â±10Â°                                               |
| `translate`      | TranslaÃ§Ã£o aleatÃ³ria de atÃ© 10%                                             |
| `scale`          | Escala aleatÃ³ria de atÃ© Â±50%                                                |
| `shear`          | InclinaÃ§Ã£o aleatÃ³ria de atÃ© 2Â°                                              |
| `patience`       | NÃºmero de Ã©pocas sem melhoria antes do Early Stopping                       |

---

## ğŸ¯ Objetivo do modelo

Detectar objetos cortantes vs. nÃ£o cortantes, usando imagens balanceadas, com mÃºltiplas classes (como `knife`, `scissor` e `cutter`)

## Resultados do treinamento

![Resultados](assets/treinamento-v5s.png)

Avaliando o nosso treinamento, podemos ver que:
O modelo YOLOv5s foi treinado por 100 Ã©pocas e teve um desempenho muito bom, especialmente considerando que se trata de uma versÃ£o leve da arquitetura. A validaÃ§Ã£o mostrou uma mÃ©dia de precisÃ£o (mAP@0.5) de 86%, com destaque para a classe tesouras, que alcanÃ§ou incrÃ­veis 95% de mAP. Isso mostra que o modelo aprendeu muito bem a identificar esse tipo de objeto.

A classe estilete tambÃ©m teve uma performance consistente, com 90% de mAP e boa revocaÃ§Ã£o. JÃ¡ a classe faca ficou um pouco abaixo, com 72% de mAP e uma revocaÃ§Ã£o mais baixa. Isso pode indicar que o modelo ainda tem dificuldades para reconhecer facas em certos contextos.

No geral, os resultados sÃ£o positivos. A inferÃªncia estÃ¡ muito rÃ¡pida, com apenas 1.5ms por imagem, o que torna o modelo ideal para aplicaÃ§Ãµes em tempo real. Com pequenos ajustes no dataset ou nos dados da classe knife, o desempenho pode melhorar ainda mais.


# InstruÃ§Ãµes de Uso

## ğŸ§° Tecnologias Utilizadas

- [Python 3.8+](https://www.python.org/) (Recomendamos Python 3.12 caso o OS seja MacOS, devido a um bug de exibiÃ§Ã£o da interface produzida com Tkinter)
- [YOLOv5 (Ultralytics)](https://github.com/ultralytics/yolov5)
- OpenCV
- Tkinter
- Torch (PyTorch)
- SMTP (para envio de e-mails)

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/marcosjsh/fiap-hackathon.git
cd fiap-hackathon
```

### 2. (Recomendado) Crie e ative um ambiente virtual

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

> âš ï¸ O `torch` pode ser instalado com suporte a GPU, se desejar:
> Consulte https://pytorch.org/get-started/locally/

---

## ğŸ“ Arquivos Esperados

Coloque seu modelo YOLOv5 treinado com nome `best.pt` na raiz do projeto:

```
fiap-hackathon/
â”œâ”€â”€ main.py
â”œâ”€â”€ best.pt  âœ…
â”œâ”€â”€ requirements.txt
```

---

## âœ‰ï¸ ConfiguraÃ§Ã£o do E-mail (Gmail)

1. Acesse: [https://myaccount.google.com/apppasswords](https://myaccount.google.com/apppasswords)
2. Gere uma senha de app para "Correio" ou "E-mail"
3. No seu cÃ³digo `main.py`, edite:

```python
email_user = "seuemail@gmail.com"
email_cod = "SENHA_DO_APP"
```

---

## â–¶ï¸ Como Usar

1. Execute o programa:

```bash
python main.py
```

2. Na interface:
   - Digite um e-mail de destino
   - Selecione uma **imagem** ou **vÃ­deo**
   - Clique em "Iniciar DetecÃ§Ã£o"
   - Se houver detecÃ§Ã£o, o sistema envia os resultados por e-mail

---

## âœ… Formatos Suportados

- **Imagens:** `.jpg`, `.jpeg`, `.png`, `.bmp`
- **VÃ­deos:** `.mp4`, `.avi`, `.mov`, `.mkv`

---

## ğŸ“¦ Estrutura de Pastas

```
frames_detectados/   # Armazena os frames/imagens com detecÃ§Ã£o
best.pt              # Seu modelo treinado YOLOv5
main.py              # CÃ³digo principal com GUI
requirements.txt     # DependÃªncias
```

---

## ğŸ›  PossÃ­veis Melhorias

- Suporte a mÃºltiplos arquivos de entrada
- IntegraÃ§Ã£o com banco de dados/logs
- Escolha de parÃ¢metros como `conf`, `iou` via interface
- Compatibilidade com diferentes provedores de e-mail

---

## ğŸ“¸ PrÃ©via da Interface

![Tela do sistema](assets/interface.png)

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© de livre uso para fins acadÃªmicos ou pessoais. Sinta-se Ã  vontade para modificar.
